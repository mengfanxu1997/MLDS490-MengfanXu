{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DwP_bUuopEOm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from collections import deque\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as T\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class mean_val:\n",
        "    def __init__(self):\n",
        "        self.k = 0\n",
        "        self.val = 0\n",
        "        self.mean = 0\n",
        "\n",
        "    def append(self,x):\n",
        "        self.k += 1\n",
        "        self.val += x\n",
        "        self.mean = self.val/self.k\n",
        "\n",
        "    def get(self):\n",
        "        return self.mean\n",
        "\n",
        "\n",
        "class logger:\n",
        "    def __init__(self):\n",
        "        self.log = dict()\n",
        "\n",
        "    def add_log(self,name):\n",
        "        self.log[name] = []\n",
        "\n",
        "    def add_item(self,name,x):\n",
        "        self.log[name].append(x)\n",
        "\n",
        "    def get_log(self,name):\n",
        "        return self.log[name]\n",
        "\n",
        "    def get_keys(self):\n",
        "        return self.log.keys()\n",
        "\n",
        "    def get_current(self,name):\n",
        "        return self.log[name][-1]\n",
        "\n",
        "def smooth(x,window_len=11,window='hanning'):\n",
        "    if window_len<3:\n",
        "        return x\n",
        "\n",
        "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
        "    #print(len(s))\n",
        "    if window == 'flat': #moving average\n",
        "        w=np.ones(window_len,'d')\n",
        "    else:\n",
        "        w=eval('np.'+window+'(window_len)')\n",
        "\n",
        "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
        "    return y\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uZ9JhQUIpkkC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self,out_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.out_dim=out_dim\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.extra = nn.Sequential(\n",
        "                       nn.Dropout(),\n",
        "                       nn.Linear(256*6*6,4096),\n",
        "                       nn.ReLU(inplace=True),\n",
        "                       nn.Dropout(),\n",
        "                       nn.Linear(4096,4096),\n",
        "                       nn.ReLU(inplace=True))\n",
        "        self.output1 = nn.Linear(4096,out_dim)\n",
        "        self.output2 = nn.Linear(4096,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        y=self.extra(x)\n",
        "        output1=self.output1(y)\n",
        "        output2=self.output2(y)\n",
        "\n",
        "        return output1,output2\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NHX6fUMzpG-4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunningMeanStd(object):\n",
        "\n",
        "    def __init__(self, epsilon=1e-4, shape=()):\n",
        "        self.mean = torch.zeros(shape, dtype = torch.float)\n",
        "        self.var = torch.ones(shape, dtype = torch.float)\n",
        "        self.count = epsilon\n",
        "\n",
        "    def update(self, x):\n",
        "        batch_mean = torch.mean(x, dim=0)\n",
        "        batch_var = torch.var(x, dim=0)\n",
        "        batch_count = x.shape[0]\n",
        "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
        "\n",
        "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
        "        delta = batch_mean - self.mean\n",
        "        tot_count = self.count + batch_count\n",
        "\n",
        "        new_mean = self.mean + delta * batch_count / tot_count\n",
        "        m_a = self.var * (self.count)\n",
        "        m_b = batch_var * (batch_count)\n",
        "        M2 = m_a + m_b + torch.square(delta) * self.count * batch_count / (self.count + batch_count)\n",
        "        new_var = M2 / (self.count + batch_count)\n",
        "\n",
        "        new_count = batch_count + self.count\n",
        "\n",
        "        self.mean = new_mean\n",
        "        self.var = new_var\n",
        "        self.count = new_count\n",
        ""
      ],
      "metadata": {
        "id": "xLlyWXXxpz53"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple, deque\n",
        "\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "xOqrbqMCmaLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "YLmmTAF1U3Cx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_states_tensor(sample, states_idx):\n",
        "    sample_len = len(sample)\n",
        "    states_tensor = torch.empty((sample_len, n_features), dtype=torch.float32, requires_grad=False)\n",
        "\n",
        "    features_range = range(n_features)\n",
        "    for i in range(sample_len):\n",
        "        for j in features_range:\n",
        "            states_tensor[i, j] = sample[i][states_idx][j].item()\n",
        "\n",
        "    return states_tensor\n"
      ],
      "metadata": {
        "id": "sr16UjT2kiBd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN_CNN:\n",
        "\n",
        "    def __init__(self, env, gamma, buffer_size):\n",
        "        self.env = env\n",
        "        acts = env.action_space\n",
        "        self.tr_1 = 1\n",
        "        self.tr_2 = 1\n",
        "        self.sum_tot_i=0\n",
        "\n",
        "        obs, _ = self.env.reset()\n",
        "\n",
        "        QNet = Model(len(obs), acts.n)\n",
        "        #QNet.classifier._modules['6']=nn.Linear(4096,env.action_space.n)\n",
        "        self.policy_model = QNet\n",
        "        self.target_model = copy.deepcopy(self.policy_model)\n",
        "        self.target_model.eval()\n",
        "\n",
        "\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.optimizer = torch.optim.Adam(self.target_model.parameters(),lr=0.00001,betas=(0.5, 0.999))\n",
        "        self.batch_size = 6\n",
        "        self.epsilon = 0.1\n",
        "        self.buffer_size = buffer_size\n",
        "        self.step_counter = 0\n",
        "        self.epsi_high = 0.9\n",
        "        self.epsi_low = 0.05\n",
        "        self.steps = 0\n",
        "        self.count = 0\n",
        "        self.decay = 200\n",
        "        self.delta=0.05\n",
        "        self.eps = self.epsi_high\n",
        "        self.update_target_step = 20\n",
        "        self.log = logger()\n",
        "        self.log.add_log('real_return')\n",
        "        self.log.add_log('avg_loss')\n",
        "        self.log.add_log('Q_reward')\n",
        "        self.replay_buffer = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "        self.obs_rms=RunningMeanStd(shape=(1,3,224,224))\n",
        "\n",
        "        self.eta = 0.05\n",
        "        self.tem=0.1\n",
        "        self.tol=1e-7\n",
        "        self.discount_factor=gamma\n",
        "        self.w1=2\n",
        "        self.w2=1\n",
        "\n",
        "    def run_episode(self):\n",
        "        obs, _ = self.env.reset()\n",
        "        acts = self.env.action_space\n",
        "        sum_r = 0\n",
        "        mean_loss = mean_val()\n",
        "        t=0\n",
        "        obs_list=[]\n",
        "        Q_max = []\n",
        "\n",
        "        done = False\n",
        "\n",
        "        state = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        while not done:\n",
        "            print(t)\n",
        "            t=t+1\n",
        "            self.steps += 1\n",
        "            self.eps = self.epsi_low + (self.epsi_high-self.epsi_low) * (np.exp(-1.0 * self.steps/self.decay))\n",
        "\n",
        "            #state = torch.tensor(tuple([x/255.0 for x in obs]),dtype=torch.float)\n",
        "            #state = torch.transpose(state,1,2).transpose(1,0)\n",
        "            #state = nn.functional.interpolate(state.unsqueeze(0),224)\n",
        "            #state = T.functional.normalize(state.squeeze(0),[0.485, 0.456, 0.406],[0.229, 0.224, 0.225]).unsqueeze(0)\n",
        "\n",
        "            #state = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "\n",
        "            Q=self.policy_model(state)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ep = torch.rand((1, )).item()\n",
        "            if (ep < self.eps):\n",
        "                action = torch.tensor([[random.randrange(acts.n)]], dtype=torch.long)\n",
        "            else:\n",
        "                with torch.no_grad():\n",
        "                  action = Q.max(1)[1]\n",
        "            new_state, reward, done, info, _ = self.env.step((action.item()))\n",
        "            sum_r = sum_r + reward\n",
        "            Q_reward = [0,0]\n",
        "            Q_max.append(Q_reward)\n",
        "\n",
        "            if done:\n",
        "              new_state = None\n",
        "            else:\n",
        "              new_state = torch.tensor(new_state, dtype=torch.float32).unsqueeze(0)\n",
        "            reward = torch.tensor([reward])\n",
        "            action = torch.tensor([action], dtype=torch.long)\n",
        "            self.replay_buffer.push(state,action,new_state, reward)\n",
        "            loss = self.update_model()\n",
        "            mean_loss.append(loss)\n",
        "            state = new_state\n",
        "\n",
        "\n",
        "\n",
        "            self.step_counter = self.step_counter + 1\n",
        "            if (self.step_counter > self.update_target_step):\n",
        "                self.target_model.load_state_dict(self.policy_model.state_dict())\n",
        "                self.step_counter = 0\n",
        "                self.target_model.eval()\n",
        "                print('updated target model')\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "\n",
        "        self.log.add_item('real_return',sum_r)\n",
        "        self.log.add_item('avg_loss',mean_loss.get())\n",
        "        self.log.add_item('Q_reward',max(Q_reward))\n",
        "\n",
        "\n",
        "    def update_model(self):\n",
        "        acts = self.env.action_space\n",
        "        num = len(self.replay_buffer)\n",
        "\n",
        "        K = np.minimum(num,self.batch_size)\n",
        "        samples = self.replay_buffer.sample(K)\n",
        "\n",
        "        batch= Transition(*zip(*samples))\n",
        "        S0 = torch.cat(batch.state)\n",
        "        A0 = torch.cat(batch.action)\n",
        "        R0 = torch.cat(batch.reward)\n",
        "        #S1 = torch.cat(batch.next_state)\n",
        "\n",
        "\n",
        "\n",
        "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), dtype=torch.bool)\n",
        "        S1 = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "          T = self.target_model(S1).max(1)[0]\n",
        "        target_q = R0 + self.gamma*T\n",
        "        policy_q = self.policy_model(S0).gather(1, A0.view(K, -1))\n",
        "        L = F.smooth_l1_loss(policy_q,target_q.unsqueeze(1))\n",
        "        L.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return L.detach().item()\n",
        "\n",
        "    def run_epoch(self):\n",
        "        self.run_episode()\n",
        "        return self.log\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2vz3rWgj6x8v"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "print(USE_CUDA)\n",
        "if USE_CUDA:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "if USE_CUDA:\n",
        "    os.environ['use_cuda'] = 'cuda'\n",
        "else:\n",
        "    os.environ['use_cuda'] = 'cpu'\n",
        "\n",
        "def get_device():\n",
        "    '''\n",
        "    get_device - returns current default device.\n",
        "\n",
        "    If Cuda is available and `os.environ['use_cuda']=='cuda'`,\n",
        "    `torch.cuda.current_device()` is returned.\n",
        "\n",
        "    Otherwise, `cpu` is returned\n",
        "\n",
        "    Returns `torch.device`\n",
        "    '''\n",
        "    if torch.cuda.is_available() and os.environ['use_cuda']=='cuda':\n",
        "        device = torch.cuda.current_device()\n",
        "    else:\n",
        "        device='cpu'\n",
        "\n",
        "    device = torch.device(device)\n",
        "    return device\n",
        "gamma = 0.95\n",
        "alg = DQN_CNN(env,gamma,100)\n",
        "num_epochs = 1\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    log = alg.run_epoch()\n",
        "    print('epoch: {}. return: {}'.format(i,np.round(log.get_current('real_return')),2))\n",
        "print(log.get_log('real_return'))\n",
        "'''\n",
        "plot the observation\n",
        "'''\n",
        "print(len(log.get_log('real_return')))\n",
        "Y = np.asarray(log.get_log('real_return'))\n",
        "#Y2 = smooth(Y)\n",
        "x = np.arange(len(Y))\n",
        "fig1 = plt.figure()\n",
        "ax1 = plt.axes()\n",
        "ax1.plot(x, Y)\n",
        "\n",
        "\n",
        "# What's this step for??\n",
        "\"\"\"\n",
        "Give a video of the game that's played by RND+DQN\n",
        "since it has the actions and observations included\n",
        "\"\"\"\n",
        "'''\n",
        "obs = env.reset()\n",
        "for t in range(1000):\n",
        "    env.render()\n",
        "    x = torch.Tensor(obs).unsqueeze(0)\n",
        "    Q = alg.model(x)\n",
        "    action = Q.argmax().detach().item()\n",
        "    new_obs, reward, done, info = env.step(action)\n",
        "    obs = new_obs\n",
        "    if done:\n",
        "        break\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "Tfs7ntmkuMot",
        "outputId": "6f5aceb3-5a80-4f13-e4ca-7f284407a0c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "epoch: 0. return: 17.0\n",
            "[17.0]\n",
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nobs = env.reset()\\nfor t in range(1000):\\n    env.render()\\n    x = torch.Tensor(obs).unsqueeze(0)\\n    Q = alg.model(x)\\n    action = Q.argmax().detach().item()\\n    new_obs, reward, done, info = env.step(action)\\n    obs = new_obs\\n    if done:\\n        break\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip install gym[atari,accept-rom-license]==0.26.0\n",
        "#!pip install ale-py\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "env = gym.make('MsPacman-v0')\n",
        "\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "if USE_CUDA:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "if USE_CUDA:\n",
        "    os.environ['use_cuda'] = 'cuda'\n",
        "else:\n",
        "    os.environ['use_cuda'] = 'cpu'\n",
        "\n",
        "def get_device():\n",
        "    '''\n",
        "    get_device - returns current default device.\n",
        "\n",
        "    If Cuda is available and `os.environ['use_cuda']=='cuda'`,\n",
        "    `torch.cuda.current_device()` is returned.\n",
        "\n",
        "    Otherwise, `cpu` is returned\n",
        "\n",
        "    Returns `torch.device`\n",
        "    '''\n",
        "    if torch.cuda.is_available() and os.environ['use_cuda']=='cuda':\n",
        "        device = torch.cuda.current_device()\n",
        "    else:\n",
        "        device='cpu'\n",
        "\n",
        "    device = torch.device(device)\n",
        "    return device\n",
        "\n",
        "device = get_device()\n",
        "\n",
        "gamma = 0.99\n",
        "alg =DQN_CNN(env,gamma,100)\n",
        "num_epochs = 1\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    log = alg.run_epoch()\n",
        "    print('epoch: {}. return: {}'.format(i,np.round(log.get_current('real_return')),2))\n",
        "print(log.get_log('real_return'))\n",
        "'''\n",
        "plot the observation\n",
        "'''\n",
        "print(len(log.get_log('real_return')))\n",
        "Y = np.asarray(log.get_log('real_return'))\n",
        "#Y2 = smooth(Y)\n",
        "x = np.arange(len(Y))\n",
        "fig1 = plt.figure()\n",
        "ax1 = plt.axes()\n",
        "ax1.plot(x, Y)\n",
        "\n",
        "\n",
        "# What's this step for??\n",
        "\"\"\"\n",
        "Give a video of the game that's played by RND+DQN\n",
        "since it has the actions and observations included\n",
        "\"\"\"\n",
        "'''\n",
        "obs = env.reset()\n",
        "for t in range(1000):\n",
        "    env.render()\n",
        "    x = torch.Tensor(obs).unsqueeze(0)\n",
        "    Q = alg.model(x)\n",
        "    action = Q.argmax().detach().item()\n",
        "    new_obs, reward, done, info = env.step(action)\n",
        "    obs = new_obs\n",
        "    if done:\n",
        "        break\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-CMS_K_svWkW",
        "outputId": "00342f5f-a016-441b-ec3a-8d7bb19c7b54"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment MsPacman-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-78e69212a5e5>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: {}. return: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'real_return'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'real_return'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7b10a146ce9c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7b10a146ce9c>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-71a6012e0efa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (33600x3 and 210x128)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIV75QSp0Jmf",
        "outputId": "38ddd895-1ec3-4c41-fedb-b8971ab745e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDYJm7AZ0Yhg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}