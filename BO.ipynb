{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "#datasets = load_data(user_ids, path_to_data)\n",
        "#train_on_clients(datasets)"
      ],
      "metadata": {
        "id": "olW1gceFvD5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4157ba82-3278-4b44-b04a-338eb872e7c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "IBmIm4h0GbwX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_data_X = 'drive/MyDrive/Colab Notebooks/train_X.npy'\n",
        "path_to_data_y = 'drive/MyDrive/Colab Notebooks/train_y.npy'\n",
        "path_to_data_test_X = 'drive/MyDrive/Colab Notebooks/test_X.npy'\n",
        "path_to_data_test_y = 'drive/MyDrive/Colab Notebooks/test_y.npy'\n",
        "datasets_X = np.load(path_to_data_X, allow_pickle=True)\n",
        "datasets_y = np.load(path_to_data_y, allow_pickle=True)\n",
        "test_X = np.load(path_to_data_test_X, allow_pickle=True)\n",
        "test_y = np.load(path_to_data_test_y, allow_pickle=True)"
      ],
      "metadata": {
        "id": "ASI0P0xWGehM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "training_X, valid_X, training_y, valid_y = train_test_split(datasets_X, datasets_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "--Tyn55tmtXJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {}\n",
        "datasets['images'] = datasets_X\n",
        "datasets['labels'] = datasets_y\n",
        "test_datasets = {}\n",
        "test_datasets['images'] = test_X\n",
        "test_datasets['labels'] = test_y\n",
        "train_datasets = {}\n",
        "train_datasets['images'] = training_X\n",
        "train_datasets['labels'] = training_y\n",
        "val_datasets = {}\n",
        "val_datasets['images'] = valid_X\n",
        "val_datasets['labels'] = valid_y\n"
      ],
      "metadata": {
        "id": "tFw1dSdk8RvV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self,act):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        if act == 'RELU':\n",
        "          self.relu = nn.ReLU()\n",
        "        elif act == 'sigmoid':\n",
        "          self.relu = nn.Sigmoid()\n",
        "        else:\n",
        "          self.relu = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Create a model instance\n",
        "# model = SimpleNN()\n"
      ],
      "metadata": {
        "id": "k3Z3u4Vc9CEJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    assert inputs.shape[0] == targets.shape[0]\n",
        "    if shuffle:\n",
        "        indices = np.arange(inputs.shape[0])\n",
        "        np.random.shuffle(indices)\n",
        "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield inputs[excerpt], targets[excerpt]"
      ],
      "metadata": {
        "id": "ksOCV0P-QxSs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "5T6Lo7inzh2T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fitness(chromosome, datasets, test_datasets, num_epochs=20):\n",
        "    mini_batch_size, activation_function = chromosome\n",
        "    lists = ['RELU', 'sigmoid', 'tanh']\n",
        "    model = SimpleNN(lists[activation_function])  # Define your model architecture here\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Modify your train_loader to use the new mini_batch_size\n",
        "    #train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train your model for one epoch\n",
        "        # ...\n",
        "        models = []\n",
        "        tmp_loss = 0\n",
        "        tmp_accuracy = 0\n",
        "\n",
        "        data = torch.tensor(datasets['images'])\n",
        "        target = torch.tensor(datasets['labels']).type(torch.LongTensor)\n",
        "        for batch in iterate_minibatches(data, target, mini_batch_size, shuffle=True):\n",
        "      # Split batch to get batch data and labels\n",
        "          batch_data, batch_labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "          outputs = model(batch_data)\n",
        "          loss = criterion(outputs, batch_labels)\n",
        "\n",
        "          #Backward pass and optimization\n",
        "          optimizer.zero_grad()  # Clear existing gradients\n",
        "          loss.backward()        # Compute gradients\n",
        "          optimizer.step()       # Update parameters\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        # Calculate F1 score on validation set\n",
        "        # ...\n",
        "        data = torch.tensor(test_datasets['images'])\n",
        "        target = torch.tensor(test_datasets['labels']).type(torch.LongTensor)\n",
        "        true_labels.extend(target.tolist())\n",
        "        output = model(data)\n",
        "        predictions.extend(torch.argmax(output,dim=1).tolist())\n",
        "        val_f1_score = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "    return val_f1_score\n"
      ],
      "metadata": {
        "id": "8IpeIkzPGMZc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvH5fzUkV9s6",
        "outputId": "8b202f19-75c7-47e2-c3f4-ae88d2c31161"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n",
            "Collecting colorama>=0.4.6 (from bayesian-optimization)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def black_box_function(batch_size, activation_param):\n",
        "    # Convert continuous parameters to discrete as needed\n",
        "    chromosome = (int(batch_size),int(activation_param))\n",
        "\n",
        "    # Example: Using the activation_param in a custom activation function\n",
        "    # model = build_model(activation_param)  # Define your model-building function\n",
        "\n",
        "    # Train your model on the training set\n",
        "    # ...\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    f1 = evaluate_fitness(chromosome, train_datasets, val_datasets) # Assume evaluate() returns the F1 score\n",
        "    return f1\n"
      ],
      "metadata": {
        "id": "3INX1869XyPG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pbounds = {\n",
        "    'batch_size': (16, 1024),  # Example range for batch size\n",
        "    'activation_param': (0,2)  # Example range for a custom activation parameter\n",
        "}"
      ],
      "metadata": {
        "id": "NtrEl_mhYYWO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=black_box_function,\n",
        "    pbounds=pbounds,\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "optimizer.maximize(\n",
        "    init_points=2,  # Number of random steps to start the optimization\n",
        "    n_iter=200,       # Number of optimization steps\n",
        ")\n",
        "\n",
        "print(optimizer.max)\n",
        "\n",
        "lists = ['RELU', 'sigmoid', 'tanh']\n",
        "best_params = optimizer.max['params']\n",
        "print(f\"Best batch size: {int(best_params['batch_size'])}\")\n",
        "print(f\"Best activation parameter: {lists[int(best_params['activation_param'])]}\")\n",
        "\n",
        "# Now, train your final model using these best parameters\n",
        "# ...\n",
        "chromosome = (int(best_params['batch_size']), int(best_params['activation_param']))\n",
        "evaluate_fitness(chromosome, datasets, test_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kP6se1vYiY6",
        "outputId": "07a7c8f7-6a76-464d-a4e8-d4ecfd38bd76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | activa... | batch_... |\n",
            "-------------------------------------------------\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m0.2979   \u001b[0m | \u001b[0m0.834    \u001b[0m | \u001b[0m742.1    \u001b[0m |\n",
            "| \u001b[95m2        \u001b[0m | \u001b[95m0.4797   \u001b[0m | \u001b[95m0.0002287\u001b[0m | \u001b[95m320.8    \u001b[0m |\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m0.5615   \u001b[0m | \u001b[95m0.0879   \u001b[0m | \u001b[95m322.1    \u001b[0m |\n",
            "| \u001b[95m4        \u001b[0m | \u001b[95m0.5852   \u001b[0m | \u001b[95m0.06365  \u001b[0m | \u001b[95m324.3    \u001b[0m |\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m0.0732   \u001b[0m | \u001b[0m1.891    \u001b[0m | \u001b[0m329.5    \u001b[0m |\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m0.2246   \u001b[0m | \u001b[0m0.03646  \u001b[0m | \u001b[0m1.022e+03\u001b[0m |\n",
            "| \u001b[95m7        \u001b[0m | \u001b[95m0.667    \u001b[0m | \u001b[95m0.7913   \u001b[0m | \u001b[95m178.7    \u001b[0m |\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m0.1396   \u001b[0m | \u001b[0m1.154    \u001b[0m | \u001b[0m182.8    \u001b[0m |\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m0.6293   \u001b[0m | \u001b[0m0.782    \u001b[0m | \u001b[0m176.4    \u001b[0m |\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m0.06734  \u001b[0m | \u001b[0m1.721    \u001b[0m | \u001b[0m171.7    \u001b[0m |\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m0.1748   \u001b[0m | \u001b[0m1.96     \u001b[0m | \u001b[0m177.6    \u001b[0m |\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m0.6575   \u001b[0m | \u001b[0m0.5427   \u001b[0m | \u001b[0m179.1    \u001b[0m |\n",
            "| \u001b[95m13       \u001b[0m | \u001b[95m0.673    \u001b[0m | \u001b[95m0.4403   \u001b[0m | \u001b[95m177.7    \u001b[0m |\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m0.06324  \u001b[0m | \u001b[0m1.863    \u001b[0m | \u001b[0m323.0    \u001b[0m |\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m0.585    \u001b[0m | \u001b[0m0.1019   \u001b[0m | \u001b[0m175.5    \u001b[0m |\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m0.4683   \u001b[0m | \u001b[0m0.19     \u001b[0m | \u001b[0m326.0    \u001b[0m |\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m0.4892   \u001b[0m | \u001b[0m0.18     \u001b[0m | \u001b[0m317.4    \u001b[0m |\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m0.08476  \u001b[0m | \u001b[0m1.81     \u001b[0m | \u001b[0m315.8    \u001b[0m |\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m0.1787   \u001b[0m | \u001b[0m1.729    \u001b[0m | \u001b[0m175.3    \u001b[0m |\n",
            "| \u001b[95m20       \u001b[0m | \u001b[95m0.6991   \u001b[0m | \u001b[95m0.1122   \u001b[0m | \u001b[95m176.8    \u001b[0m |\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m0.2205   \u001b[0m | \u001b[0m0.439    \u001b[0m | \u001b[0m855.5    \u001b[0m |\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m0.02415  \u001b[0m | \u001b[0m1.021    \u001b[0m | \u001b[0m800.8    \u001b[0m |\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m0.02516  \u001b[0m | \u001b[0m1.688    \u001b[0m | \u001b[0m630.6    \u001b[0m |\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m0.4168   \u001b[0m | \u001b[0m0.9532   \u001b[0m | \u001b[0m449.0    \u001b[0m |\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m0.02951  \u001b[0m | \u001b[0m1.346    \u001b[0m | \u001b[0m452.1    \u001b[0m |\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m0.03185  \u001b[0m | \u001b[0m1.762    \u001b[0m | \u001b[0m446.4    \u001b[0m |\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m0.09351  \u001b[0m | \u001b[0m1.269    \u001b[0m | \u001b[0m318.8    \u001b[0m |\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m0.1846   \u001b[0m | \u001b[0m1.717    \u001b[0m | \u001b[0m180.1    \u001b[0m |\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m0.07105  \u001b[0m | \u001b[0m1.938    \u001b[0m | \u001b[0m416.6    \u001b[0m |\n",
            "| \u001b[0m30       \u001b[0m | \u001b[0m0.6897   \u001b[0m | \u001b[0m0.009209 \u001b[0m | \u001b[0m178.8    \u001b[0m |\n",
            "| \u001b[0m31       \u001b[0m | \u001b[0m0.06455  \u001b[0m | \u001b[0m1.386    \u001b[0m | \u001b[0m601.3    \u001b[0m |\n",
            "| \u001b[0m32       \u001b[0m | \u001b[0m0.3254   \u001b[0m | \u001b[0m1.554    \u001b[0m | \u001b[0m106.2    \u001b[0m |\n",
            "| \u001b[95m33       \u001b[0m | \u001b[95m0.7864   \u001b[0m | \u001b[95m0.9106   \u001b[0m | \u001b[95m101.7    \u001b[0m |\n",
            "| \u001b[0m34       \u001b[0m | \u001b[0m0.2773   \u001b[0m | \u001b[0m1.817    \u001b[0m | \u001b[0m100.6    \u001b[0m |\n",
            "| \u001b[95m35       \u001b[0m | \u001b[95m0.7906   \u001b[0m | \u001b[95m0.2318   \u001b[0m | \u001b[95m102.7    \u001b[0m |\n",
            "| \u001b[0m36       \u001b[0m | \u001b[0m0.1865   \u001b[0m | \u001b[0m1.59     \u001b[0m | \u001b[0m103.0    \u001b[0m |\n",
            "| \u001b[0m37       \u001b[0m | \u001b[0m0.7848   \u001b[0m | \u001b[0m0.1068   \u001b[0m | \u001b[0m101.8    \u001b[0m |\n",
            "| \u001b[0m38       \u001b[0m | \u001b[0m0.7871   \u001b[0m | \u001b[0m0.1156   \u001b[0m | \u001b[0m100.6    \u001b[0m |\n",
            "| \u001b[0m39       \u001b[0m | \u001b[0m0.7875   \u001b[0m | \u001b[0m0.2881   \u001b[0m | \u001b[0m99.34    \u001b[0m |\n",
            "| \u001b[0m40       \u001b[0m | \u001b[0m0.7482   \u001b[0m | \u001b[0m0.7481   \u001b[0m | \u001b[0m97.88    \u001b[0m |\n",
            "| \u001b[0m41       \u001b[0m | \u001b[0m0.7752   \u001b[0m | \u001b[0m0.3802   \u001b[0m | \u001b[0m95.96    \u001b[0m |\n",
            "| \u001b[0m42       \u001b[0m | \u001b[0m0.2029   \u001b[0m | \u001b[0m1.892    \u001b[0m | \u001b[0m96.31    \u001b[0m |\n",
            "| \u001b[0m43       \u001b[0m | \u001b[0m0.7751   \u001b[0m | \u001b[0m0.5398   \u001b[0m | \u001b[0m94.17    \u001b[0m |\n",
            "| \u001b[95m44       \u001b[0m | \u001b[95m0.7976   \u001b[0m | \u001b[95m0.02538  \u001b[0m | \u001b[95m92.87    \u001b[0m |\n",
            "| \u001b[0m45       \u001b[0m | \u001b[0m0.3268   \u001b[0m | \u001b[0m1.648    \u001b[0m | \u001b[0m92.49    \u001b[0m |\n",
            "| \u001b[0m46       \u001b[0m | \u001b[0m0.7865   \u001b[0m | \u001b[0m0.1359   \u001b[0m | \u001b[0m97.44    \u001b[0m |\n",
            "| \u001b[0m47       \u001b[0m | \u001b[0m0.7872   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m94.95    \u001b[0m |\n",
            "| \u001b[0m48       \u001b[0m | \u001b[0m0.7908   \u001b[0m | \u001b[0m0.02177  \u001b[0m | \u001b[0m90.96    \u001b[0m |\n",
            "| \u001b[0m49       \u001b[0m | \u001b[0m0.7877   \u001b[0m | \u001b[0m0.1349   \u001b[0m | \u001b[0m89.17    \u001b[0m |\n",
            "| \u001b[0m50       \u001b[0m | \u001b[0m0.2271   \u001b[0m | \u001b[0m1.981    \u001b[0m | \u001b[0m89.09    \u001b[0m |\n",
            "| \u001b[0m51       \u001b[0m | \u001b[0m0.7768   \u001b[0m | \u001b[0m0.1793   \u001b[0m | \u001b[0m87.06    \u001b[0m |\n",
            "| \u001b[0m52       \u001b[0m | \u001b[0m0.7786   \u001b[0m | \u001b[0m0.03791  \u001b[0m | \u001b[0m84.91    \u001b[0m |\n",
            "| \u001b[0m53       \u001b[0m | \u001b[0m0.4378   \u001b[0m | \u001b[0m1.603    \u001b[0m | \u001b[0m85.28    \u001b[0m |\n",
            "| \u001b[95m54       \u001b[0m | \u001b[95m0.8184   \u001b[0m | \u001b[95m0.2228   \u001b[0m | \u001b[95m83.44    \u001b[0m |\n",
            "| \u001b[0m55       \u001b[0m | \u001b[0m0.7749   \u001b[0m | \u001b[0m0.142    \u001b[0m | \u001b[0m81.36    \u001b[0m |\n",
            "| \u001b[0m56       \u001b[0m | \u001b[0m0.3465   \u001b[0m | \u001b[0m1.637    \u001b[0m | \u001b[0m82.13    \u001b[0m |\n",
            "| \u001b[0m57       \u001b[0m | \u001b[0m0.8153   \u001b[0m | \u001b[0m0.1308   \u001b[0m | \u001b[0m78.95    \u001b[0m |\n",
            "| \u001b[95m58       \u001b[0m | \u001b[95m0.8214   \u001b[0m | \u001b[95m0.7569   \u001b[0m | \u001b[95m77.34    \u001b[0m |\n",
            "| \u001b[0m59       \u001b[0m | \u001b[0m0.323    \u001b[0m | \u001b[0m1.998    \u001b[0m | \u001b[0m79.14    \u001b[0m |\n",
            "| \u001b[0m60       \u001b[0m | \u001b[0m0.8089   \u001b[0m | \u001b[0m0.1437   \u001b[0m | \u001b[0m75.64    \u001b[0m |\n",
            "| \u001b[0m61       \u001b[0m | \u001b[0m0.3441   \u001b[0m | \u001b[0m1.692    \u001b[0m | \u001b[0m75.14    \u001b[0m |\n",
            "| \u001b[0m62       \u001b[0m | \u001b[0m0.7934   \u001b[0m | \u001b[0m0.02614  \u001b[0m | \u001b[0m77.92    \u001b[0m |\n",
            "| \u001b[0m63       \u001b[0m | \u001b[0m0.04234  \u001b[0m | \u001b[0m1.317    \u001b[0m | \u001b[0m510.2    \u001b[0m |\n",
            "| \u001b[0m64       \u001b[0m | \u001b[0m0.1016   \u001b[0m | \u001b[0m1.392    \u001b[0m | \u001b[0m231.3    \u001b[0m |\n",
            "| \u001b[0m65       \u001b[0m | \u001b[0m0.4775   \u001b[0m | \u001b[0m0.2626   \u001b[0m | \u001b[0m265.1    \u001b[0m |\n",
            "| \u001b[0m66       \u001b[0m | \u001b[0m0.4936   \u001b[0m | \u001b[0m0.08809  \u001b[0m | \u001b[0m269.9    \u001b[0m |\n",
            "| \u001b[0m67       \u001b[0m | \u001b[0m0.07425  \u001b[0m | \u001b[0m1.174    \u001b[0m | \u001b[0m274.2    \u001b[0m |\n",
            "| \u001b[0m68       \u001b[0m | \u001b[0m0.1548   \u001b[0m | \u001b[0m1.782    \u001b[0m | \u001b[0m260.7    \u001b[0m |\n",
            "| \u001b[0m69       \u001b[0m | \u001b[0m0.02315  \u001b[0m | \u001b[0m1.801    \u001b[0m | \u001b[0m914.2    \u001b[0m |\n",
            "| \u001b[95m70       \u001b[0m | \u001b[95m0.838    \u001b[0m | \u001b[95m0.7701   \u001b[0m | \u001b[95m30.09    \u001b[0m |\n",
            "| \u001b[0m71       \u001b[0m | \u001b[0m0.6831   \u001b[0m | \u001b[0m1.516    \u001b[0m | \u001b[0m31.72    \u001b[0m |\n",
            "| \u001b[0m72       \u001b[0m | \u001b[0m0.7369   \u001b[0m | \u001b[0m1.968    \u001b[0m | \u001b[0m28.61    \u001b[0m |\n",
            "| \u001b[95m73       \u001b[0m | \u001b[95m0.8501   \u001b[0m | \u001b[95m0.1439   \u001b[0m | \u001b[95m28.39    \u001b[0m |\n",
            "| \u001b[95m74       \u001b[0m | \u001b[95m0.8503   \u001b[0m | \u001b[95m0.2904   \u001b[0m | \u001b[95m26.09    \u001b[0m |\n",
            "| \u001b[0m75       \u001b[0m | \u001b[0m0.7406   \u001b[0m | \u001b[0m1.843    \u001b[0m | \u001b[0m26.37    \u001b[0m |\n",
            "| \u001b[95m76       \u001b[0m | \u001b[95m0.8564   \u001b[0m | \u001b[95m0.9603   \u001b[0m | \u001b[95m24.11    \u001b[0m |\n",
            "| \u001b[0m77       \u001b[0m | \u001b[0m0.8527   \u001b[0m | \u001b[0m0.1316   \u001b[0m | \u001b[0m22.27    \u001b[0m |\n",
            "| \u001b[0m78       \u001b[0m | \u001b[0m0.7619   \u001b[0m | \u001b[0m1.951    \u001b[0m | \u001b[0m22.24    \u001b[0m |\n",
            "| \u001b[0m79       \u001b[0m | \u001b[0m0.7331   \u001b[0m | \u001b[0m0.03973  \u001b[0m | \u001b[0m19.86    \u001b[0m |\n",
            "| \u001b[0m80       \u001b[0m | \u001b[0m0.8143   \u001b[0m | \u001b[0m1.907    \u001b[0m | \u001b[0m17.62    \u001b[0m |\n",
            "| \u001b[95m81       \u001b[0m | \u001b[95m0.8682   \u001b[0m | \u001b[95m0.2569   \u001b[0m | \u001b[95m16.05    \u001b[0m |\n",
            "| \u001b[95m82       \u001b[0m | \u001b[95m0.8803   \u001b[0m | \u001b[95m0.467    \u001b[0m | \u001b[95m17.64    \u001b[0m |\n",
            "| \u001b[0m83       \u001b[0m | \u001b[0m0.8183   \u001b[0m | \u001b[0m1.846    \u001b[0m | \u001b[0m16.01    \u001b[0m |\n",
            "| \u001b[0m84       \u001b[0m | \u001b[0m0.8617   \u001b[0m | \u001b[0m0.01114  \u001b[0m | \u001b[0m35.25    \u001b[0m |\n",
            "| \u001b[0m85       \u001b[0m | \u001b[0m0.6284   \u001b[0m | \u001b[0m1.865    \u001b[0m | \u001b[0m36.42    \u001b[0m |\n",
            "| \u001b[0m86       \u001b[0m | \u001b[0m0.8359   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m37.87    \u001b[0m |\n",
            "| \u001b[0m87       \u001b[0m | \u001b[0m0.8402   \u001b[0m | \u001b[0m0.05742  \u001b[0m | \u001b[0m40.23    \u001b[0m |\n",
            "| \u001b[0m88       \u001b[0m | \u001b[0m0.6327   \u001b[0m | \u001b[0m1.909    \u001b[0m | \u001b[0m40.0     \u001b[0m |\n",
            "| \u001b[0m89       \u001b[0m | \u001b[0m0.8535   \u001b[0m | \u001b[0m0.1237   \u001b[0m | \u001b[0m42.8     \u001b[0m |\n",
            "| \u001b[0m90       \u001b[0m | \u001b[0m0.5798   \u001b[0m | \u001b[0m1.873    \u001b[0m | \u001b[0m44.72    \u001b[0m |\n",
            "| \u001b[0m91       \u001b[0m | \u001b[0m0.8155   \u001b[0m | \u001b[0m0.05287  \u001b[0m | \u001b[0m49.82    \u001b[0m |\n",
            "| \u001b[0m92       \u001b[0m | \u001b[0m0.436    \u001b[0m | \u001b[0m1.483    \u001b[0m | \u001b[0m51.89    \u001b[0m |\n",
            "| \u001b[0m93       \u001b[0m | \u001b[0m0.8253   \u001b[0m | \u001b[0m0.7991   \u001b[0m | \u001b[0m47.72    \u001b[0m |\n",
            "| \u001b[0m94       \u001b[0m | \u001b[0m0.4741   \u001b[0m | \u001b[0m1.947    \u001b[0m | \u001b[0m49.04    \u001b[0m |\n",
            "| \u001b[0m95       \u001b[0m | \u001b[0m0.8313   \u001b[0m | \u001b[0m0.01865  \u001b[0m | \u001b[0m45.52    \u001b[0m |\n",
            "| \u001b[0m96       \u001b[0m | \u001b[0m0.242    \u001b[0m | \u001b[0m0.7238   \u001b[0m | \u001b[0m699.4    \u001b[0m |\n",
            "| \u001b[0m97       \u001b[0m | \u001b[0m0.23     \u001b[0m | \u001b[0m0.1373   \u001b[0m | \u001b[0m957.5    \u001b[0m |\n",
            "| \u001b[0m98       \u001b[0m | \u001b[0m0.8497   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m33.25    \u001b[0m |\n",
            "| \u001b[0m99       \u001b[0m | \u001b[0m0.3138   \u001b[0m | \u001b[0m0.5632   \u001b[0m | \u001b[0m556.8    \u001b[0m |\n",
            "| \u001b[0m100      \u001b[0m | \u001b[0m0.4868   \u001b[0m | \u001b[0m0.6616   \u001b[0m | \u001b[0m371.1    \u001b[0m |\n",
            "| \u001b[0m101      \u001b[0m | \u001b[0m0.3412   \u001b[0m | \u001b[0m0.9779   \u001b[0m | \u001b[0m665.6    \u001b[0m |\n",
            "| \u001b[0m102      \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m1.827    \u001b[0m | \u001b[0m138.4    \u001b[0m |\n",
            "| \u001b[0m103      \u001b[0m | \u001b[0m0.03368  \u001b[0m | \u001b[0m1.25     \u001b[0m | \u001b[0m990.1    \u001b[0m |\n",
            "| \u001b[0m104      \u001b[0m | \u001b[0m0.03342  \u001b[0m | \u001b[0m1.555    \u001b[0m | \u001b[0m771.1    \u001b[0m |\n",
            "| \u001b[0m105      \u001b[0m | \u001b[0m0.2499   \u001b[0m | \u001b[0m0.1152   \u001b[0m | \u001b[0m884.5    \u001b[0m |\n",
            "| \u001b[0m106      \u001b[0m | \u001b[0m0.4192   \u001b[0m | \u001b[0m0.124    \u001b[0m | \u001b[0m481.1    \u001b[0m |\n",
            "| \u001b[0m107      \u001b[0m | \u001b[0m0.02322  \u001b[0m | \u001b[0m1.852    \u001b[0m | \u001b[0m828.4    \u001b[0m |\n",
            "| \u001b[0m108      \u001b[0m | \u001b[0m0.5715   \u001b[0m | \u001b[0m0.1143   \u001b[0m | \u001b[0m206.9    \u001b[0m |\n",
            "| \u001b[0m109      \u001b[0m | \u001b[0m0.1748   \u001b[0m | \u001b[0m1.898    \u001b[0m | \u001b[0m202.8    \u001b[0m |\n",
            "| \u001b[0m110      \u001b[0m | \u001b[0m0.5953   \u001b[0m | \u001b[0m0.4132   \u001b[0m | \u001b[0m211.1    \u001b[0m |\n",
            "| \u001b[0m111      \u001b[0m | \u001b[0m0.1167   \u001b[0m | \u001b[0m1.418    \u001b[0m | \u001b[0m215.1    \u001b[0m |\n",
            "| \u001b[0m112      \u001b[0m | \u001b[0m0.5352   \u001b[0m | \u001b[0m0.1776   \u001b[0m | \u001b[0m392.2    \u001b[0m |\n",
            "| \u001b[0m113      \u001b[0m | \u001b[0m0.03022  \u001b[0m | \u001b[0m1.923    \u001b[0m | \u001b[0m387.3    \u001b[0m |\n",
            "| \u001b[0m114      \u001b[0m | \u001b[0m0.4628   \u001b[0m | \u001b[0m0.03381  \u001b[0m | \u001b[0m396.7    \u001b[0m |\n",
            "| \u001b[0m115      \u001b[0m | \u001b[0m0.03356  \u001b[0m | \u001b[0m1.875    \u001b[0m | \u001b[0m533.8    \u001b[0m |\n",
            "| \u001b[0m116      \u001b[0m | \u001b[0m0.0489   \u001b[0m | \u001b[0m1.125    \u001b[0m | \u001b[0m352.5    \u001b[0m |\n",
            "| \u001b[0m117      \u001b[0m | \u001b[0m0.3924   \u001b[0m | \u001b[0m0.3755   \u001b[0m | \u001b[0m578.6    \u001b[0m |\n",
            "| \u001b[0m118      \u001b[0m | \u001b[0m0.02221  \u001b[0m | \u001b[0m1.929    \u001b[0m | \u001b[0m721.0    \u001b[0m |\n",
            "| \u001b[0m119      \u001b[0m | \u001b[0m0.2692   \u001b[0m | \u001b[0m0.3656   \u001b[0m | \u001b[0m936.0    \u001b[0m |\n",
            "| \u001b[0m120      \u001b[0m | \u001b[0m0.5788   \u001b[0m | \u001b[0m0.04615  \u001b[0m | \u001b[0m294.9    \u001b[0m |\n",
            "| \u001b[0m121      \u001b[0m | \u001b[0m0.08542  \u001b[0m | \u001b[0m1.743    \u001b[0m | \u001b[0m298.5    \u001b[0m |\n",
            "| \u001b[0m122      \u001b[0m | \u001b[0m0.6156   \u001b[0m | \u001b[0m0.3827   \u001b[0m | \u001b[0m290.9    \u001b[0m |\n",
            "| \u001b[0m123      \u001b[0m | \u001b[0m0.1095   \u001b[0m | \u001b[0m1.687    \u001b[0m | \u001b[0m287.4    \u001b[0m |\n",
            "| \u001b[0m124      \u001b[0m | \u001b[0m0.6495   \u001b[0m | \u001b[0m1.993    \u001b[0m | \u001b[0m34.07    \u001b[0m |\n",
            "| \u001b[0m125      \u001b[0m | \u001b[0m0.5741   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m364.7    \u001b[0m |\n",
            "| \u001b[0m126      \u001b[0m | \u001b[0m0.4518   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m361.3    \u001b[0m |\n",
            "| \u001b[0m127      \u001b[0m | \u001b[0m0.2451   \u001b[0m | \u001b[0m0.3663   \u001b[0m | \u001b[0m648.7    \u001b[0m |\n",
            "| \u001b[0m128      \u001b[0m | \u001b[0m0.7578   \u001b[0m | \u001b[0m1.986    \u001b[0m | \u001b[0m19.89    \u001b[0m |\n",
            "| \u001b[0m129      \u001b[0m | \u001b[0m0.03092  \u001b[0m | \u001b[0m1.353    \u001b[0m | \u001b[0m682.3    \u001b[0m |\n",
            "| \u001b[0m130      \u001b[0m | \u001b[0m0.7685   \u001b[0m | \u001b[0m0.2219   \u001b[0m | \u001b[0m121.1    \u001b[0m |\n",
            "| \u001b[0m131      \u001b[0m | \u001b[0m0.1366   \u001b[0m | \u001b[0m1.395    \u001b[0m | \u001b[0m123.4    \u001b[0m |\n",
            "| \u001b[0m132      \u001b[0m | \u001b[0m0.7486   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m118.8    \u001b[0m |\n",
            "| \u001b[0m133      \u001b[0m | \u001b[0m0.1981   \u001b[0m | \u001b[0m1.745    \u001b[0m | \u001b[0m119.3    \u001b[0m |\n",
            "| \u001b[0m134      \u001b[0m | \u001b[0m0.7734   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m115.7    \u001b[0m |\n",
            "| \u001b[0m135      \u001b[0m | \u001b[0m0.7656   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m113.1    \u001b[0m |\n",
            "| \u001b[0m136      \u001b[0m | \u001b[0m0.2145   \u001b[0m | \u001b[0m1.926    \u001b[0m | \u001b[0m114.3    \u001b[0m |\n",
            "| \u001b[0m137      \u001b[0m | \u001b[0m0.7643   \u001b[0m | \u001b[0m0.8809   \u001b[0m | \u001b[0m110.4    \u001b[0m |\n",
            "| \u001b[0m138      \u001b[0m | \u001b[0m0.6738   \u001b[0m | \u001b[0m0.04825  \u001b[0m | \u001b[0m154.5    \u001b[0m |\n",
            "| \u001b[0m139      \u001b[0m | \u001b[0m0.6566   \u001b[0m | \u001b[0m0.5234   \u001b[0m | \u001b[0m157.5    \u001b[0m |\n",
            "| \u001b[0m140      \u001b[0m | \u001b[0m0.2002   \u001b[0m | \u001b[0m1.628    \u001b[0m | \u001b[0m151.7    \u001b[0m |\n",
            "| \u001b[0m141      \u001b[0m | \u001b[0m0.6516   \u001b[0m | \u001b[0m0.06137  \u001b[0m | \u001b[0m160.8    \u001b[0m |\n",
            "| \u001b[0m142      \u001b[0m | \u001b[0m0.09911  \u001b[0m | \u001b[0m1.911    \u001b[0m | \u001b[0m163.6    \u001b[0m |\n",
            "| \u001b[0m143      \u001b[0m | \u001b[0m0.2293   \u001b[0m | \u001b[0m0.2764   \u001b[0m | \u001b[0m973.3    \u001b[0m |\n",
            "| \u001b[0m144      \u001b[0m | \u001b[0m0.1093   \u001b[0m | \u001b[0m1.906    \u001b[0m | \u001b[0m292.9    \u001b[0m |\n",
            "| \u001b[0m145      \u001b[0m | \u001b[0m0.02313  \u001b[0m | \u001b[0m1.818    \u001b[0m | \u001b[0m1.006e+03\u001b[0m |\n",
            "| \u001b[0m146      \u001b[0m | \u001b[0m0.4526   \u001b[0m | \u001b[0m0.1031   \u001b[0m | \u001b[0m367.3    \u001b[0m |\n",
            "| \u001b[0m147      \u001b[0m | \u001b[0m0.06626  \u001b[0m | \u001b[0m1.471    \u001b[0m | \u001b[0m376.7    \u001b[0m |\n",
            "| \u001b[0m148      \u001b[0m | \u001b[0m0.1907   \u001b[0m | \u001b[0m1.961    \u001b[0m | \u001b[0m208.9    \u001b[0m |\n",
            "| \u001b[0m149      \u001b[0m | \u001b[0m0.03914  \u001b[0m | \u001b[0m1.692    \u001b[0m | \u001b[0m494.4    \u001b[0m |\n",
            "| \u001b[0m150      \u001b[0m | \u001b[0m0.223    \u001b[0m | \u001b[0m1.981    \u001b[0m | \u001b[0m156.0    \u001b[0m |\n",
            "| \u001b[0m151      \u001b[0m | \u001b[0m0.6127   \u001b[0m | \u001b[0m1.652    \u001b[0m | \u001b[0m42.1     \u001b[0m |\n",
            "| \u001b[0m152      \u001b[0m | \u001b[0m0.04802  \u001b[0m | \u001b[0m1.883    \u001b[0m | \u001b[0m467.6    \u001b[0m |\n",
            "| \u001b[0m153      \u001b[0m | \u001b[0m0.03065  \u001b[0m | \u001b[0m1.907    \u001b[0m | \u001b[0m870.2    \u001b[0m |\n",
            "| \u001b[0m154      \u001b[0m | \u001b[0m0.7765   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m108.7    \u001b[0m |\n",
            "| \u001b[0m155      \u001b[0m | \u001b[0m0.03768  \u001b[0m | \u001b[0m1.849    \u001b[0m | \u001b[0m899.1    \u001b[0m |\n",
            "| \u001b[0m156      \u001b[0m | \u001b[0m0.8515   \u001b[0m | \u001b[0m0.005424 \u001b[0m | \u001b[0m31.26    \u001b[0m |\n",
            "| \u001b[0m157      \u001b[0m | \u001b[0m0.2637   \u001b[0m | \u001b[0m0.128    \u001b[0m | \u001b[0m756.1    \u001b[0m |\n",
            "| \u001b[0m158      \u001b[0m | \u001b[0m0.4605   \u001b[0m | \u001b[0m0.2622   \u001b[0m | \u001b[0m431.4    \u001b[0m |\n",
            "| \u001b[0m159      \u001b[0m | \u001b[0m0.6218   \u001b[0m | \u001b[0m0.2413   \u001b[0m | \u001b[0m246.0    \u001b[0m |\n",
            "| \u001b[0m160      \u001b[0m | \u001b[0m0.5876   \u001b[0m | \u001b[0m0.3588   \u001b[0m | \u001b[0m249.3    \u001b[0m |\n",
            "| \u001b[0m161      \u001b[0m | \u001b[0m0.1089   \u001b[0m | \u001b[0m1.139    \u001b[0m | \u001b[0m242.5    \u001b[0m |\n",
            "| \u001b[0m162      \u001b[0m | \u001b[0m0.09612  \u001b[0m | \u001b[0m1.935    \u001b[0m | \u001b[0m252.6    \u001b[0m |\n",
            "| \u001b[0m163      \u001b[0m | \u001b[0m0.247    \u001b[0m | \u001b[0m0.3478   \u001b[0m | \u001b[0m786.1    \u001b[0m |\n",
            "| \u001b[0m164      \u001b[0m | \u001b[0m0.304    \u001b[0m | \u001b[0m0.2554   \u001b[0m | \u001b[0m615.7    \u001b[0m |\n",
            "| \u001b[0m165      \u001b[0m | \u001b[0m0.07627  \u001b[0m | \u001b[0m1.923    \u001b[0m | \u001b[0m403.7    \u001b[0m |\n",
            "| \u001b[0m166      \u001b[0m | \u001b[0m0.2989   \u001b[0m | \u001b[0m0.4634   \u001b[0m | \u001b[0m842.3    \u001b[0m |\n",
            "| \u001b[0m167      \u001b[0m | \u001b[0m0.02415  \u001b[0m | \u001b[0m1.781    \u001b[0m | \u001b[0m814.6    \u001b[0m |\n",
            "| \u001b[0m168      \u001b[0m | \u001b[0m0.8292   \u001b[0m | \u001b[0m0.1542   \u001b[0m | \u001b[0m63.09    \u001b[0m |\n",
            "| \u001b[0m169      \u001b[0m | \u001b[0m0.381    \u001b[0m | \u001b[0m1.114    \u001b[0m | \u001b[0m64.97    \u001b[0m |\n",
            "| \u001b[0m170      \u001b[0m | \u001b[0m0.833    \u001b[0m | \u001b[0m0.2667   \u001b[0m | \u001b[0m61.02    \u001b[0m |\n",
            "| \u001b[0m171      \u001b[0m | \u001b[0m0.5277   \u001b[0m | \u001b[0m1.991    \u001b[0m | \u001b[0m61.86    \u001b[0m |\n",
            "| \u001b[0m172      \u001b[0m | \u001b[0m0.8295   \u001b[0m | \u001b[0m0.1465   \u001b[0m | \u001b[0m58.36    \u001b[0m |\n",
            "| \u001b[0m173      \u001b[0m | \u001b[0m0.3979   \u001b[0m | \u001b[0m1.992    \u001b[0m | \u001b[0m57.32    \u001b[0m |\n",
            "| \u001b[0m174      \u001b[0m | \u001b[0m0.02624  \u001b[0m | \u001b[0m1.825    \u001b[0m | \u001b[0m567.9    \u001b[0m |\n",
            "| \u001b[0m175      \u001b[0m | \u001b[0m0.04279  \u001b[0m | \u001b[0m1.935    \u001b[0m | \u001b[0m588.9    \u001b[0m |\n",
            "| \u001b[0m176      \u001b[0m | \u001b[0m0.3445   \u001b[0m | \u001b[0m0.3405   \u001b[0m | \u001b[0m545.9    \u001b[0m |\n",
            "| \u001b[0m177      \u001b[0m | \u001b[0m0.3717   \u001b[0m | \u001b[0m0.2529   \u001b[0m | \u001b[0m522.1    \u001b[0m |\n",
            "| \u001b[0m178      \u001b[0m | \u001b[0m0.5343   \u001b[0m | \u001b[0m0.1159   \u001b[0m | \u001b[0m341.1    \u001b[0m |\n",
            "| \u001b[0m179      \u001b[0m | \u001b[0m0.0261   \u001b[0m | \u001b[0m1.406    \u001b[0m | \u001b[0m337.6    \u001b[0m |\n",
            "| \u001b[0m180      \u001b[0m | \u001b[0m0.5889   \u001b[0m | \u001b[0m0.3109   \u001b[0m | \u001b[0m344.5    \u001b[0m |\n",
            "| \u001b[0m181      \u001b[0m | \u001b[0m0.8311   \u001b[0m | \u001b[0m0.02909  \u001b[0m | \u001b[0m59.64    \u001b[0m |\n",
            "| \u001b[0m182      \u001b[0m | \u001b[0m0.0289   \u001b[0m | \u001b[0m1.865    \u001b[0m | \u001b[0m947.0    \u001b[0m |\n",
            "| \u001b[0m183      \u001b[0m | \u001b[0m0.02227  \u001b[0m | \u001b[0m1.788    \u001b[0m | \u001b[0m925.6    \u001b[0m |\n",
            "| \u001b[0m184      \u001b[0m | \u001b[0m0.2813   \u001b[0m | \u001b[0m0.02834  \u001b[0m | \u001b[0m709.8    \u001b[0m |\n",
            "| \u001b[0m185      \u001b[0m | \u001b[0m0.3944   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m732.2    \u001b[0m |\n",
            "| \u001b[0m186      \u001b[0m | \u001b[0m0.4137   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m425.9    \u001b[0m |\n",
            "| \u001b[0m187      \u001b[0m | \u001b[0m0.02243  \u001b[0m | \u001b[0m1.955    \u001b[0m | \u001b[0m436.6    \u001b[0m |\n",
            "| \u001b[0m188      \u001b[0m | \u001b[0m0.6234   \u001b[0m | \u001b[0m0.1086   \u001b[0m | \u001b[0m192.8    \u001b[0m |\n",
            "| \u001b[0m189      \u001b[0m | \u001b[0m0.17     \u001b[0m | \u001b[0m1.77     \u001b[0m | \u001b[0m195.4    \u001b[0m |\n",
            "| \u001b[0m190      \u001b[0m | \u001b[0m0.6675   \u001b[0m | \u001b[0m0.03723  \u001b[0m | \u001b[0m189.8    \u001b[0m |\n",
            "| \u001b[0m191      \u001b[0m | \u001b[0m0.1463   \u001b[0m | \u001b[0m1.966    \u001b[0m | \u001b[0m191.2    \u001b[0m |\n",
            "| \u001b[0m192      \u001b[0m | \u001b[0m0.6648   \u001b[0m | \u001b[0m0.4429   \u001b[0m | \u001b[0m187.1    \u001b[0m |\n",
            "| \u001b[0m193      \u001b[0m | \u001b[0m0.8762   \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m24.29    \u001b[0m |\n",
            "| \u001b[0m194      \u001b[0m | \u001b[0m0.6709   \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m247.5    \u001b[0m |\n",
            "| \u001b[0m195      \u001b[0m | \u001b[0m0.02521  \u001b[0m | \u001b[0m1.924    \u001b[0m | \u001b[0m657.5    \u001b[0m |\n",
            "| \u001b[0m196      \u001b[0m | \u001b[0m0.3078   \u001b[0m | \u001b[0m0.1305   \u001b[0m | \u001b[0m639.8    \u001b[0m |\n",
            "| \u001b[0m197      \u001b[0m | \u001b[0m0.2195   \u001b[0m | \u001b[0m0.007798 \u001b[0m | \u001b[0m673.3    \u001b[0m |\n",
            "| \u001b[0m198      \u001b[0m | \u001b[0m0.02211  \u001b[0m | \u001b[0m1.897    \u001b[0m | \u001b[0m691.3    \u001b[0m |\n",
            "| \u001b[0m199      \u001b[0m | \u001b[0m0.5477   \u001b[0m | \u001b[0m0.7358   \u001b[0m | \u001b[0m307.4    \u001b[0m |\n",
            "| \u001b[0m200      \u001b[0m | \u001b[0m0.03053  \u001b[0m | \u001b[0m1.844    \u001b[0m | \u001b[0m981.2    \u001b[0m |\n",
            "| \u001b[0m201      \u001b[0m | \u001b[0m0.02206  \u001b[0m | \u001b[0m1.904    \u001b[0m | \u001b[0m965.5    \u001b[0m |\n",
            "| \u001b[0m202      \u001b[0m | \u001b[0m0.8304   \u001b[0m | \u001b[0m0.005205 \u001b[0m | \u001b[0m48.26    \u001b[0m |\n",
            "=================================================\n",
            "{'target': 0.8803194012097328, 'params': {'activation_param': 0.46704834631691305, 'batch_size': 17.6366745022601}}\n",
            "Best batch size: 17\n",
            "Best activation parameter: RELU\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8570409626457165"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_fitness(chromosome, datasets, test_datasets, num_epochs=100):\n",
        "    mini_batch_size, activation_function = chromosome\n",
        "    lists = ['RELU', 'sigmoid', 'tanh']\n",
        "    model = SimpleNN('RELU')  # Define your model architecture here\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Modify your train_loader to use the new mini_batch_size\n",
        "    #train_loader = DataLoader(train_dataset, batch_size=mini_batch_size, shuffle=True)\n",
        "\n",
        "    f1 = []\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train your model for one epoch\n",
        "        # ...\n",
        "        models = []\n",
        "        tmp_loss = 0\n",
        "        tmp_accuracy = 0\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        data = torch.tensor(datasets['images'])\n",
        "        target = torch.tensor(datasets['labels']).type(torch.LongTensor)\n",
        "        for batch in iterate_minibatches(data, target, mini_batch_size, shuffle=True):\n",
        "      # Split batch to get batch data and labels\n",
        "          batch_data, batch_labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "          outputs = model(batch_data)\n",
        "          loss = criterion(outputs, batch_labels)\n",
        "          pred = torch.argmax(outputs,dim=1)\n",
        "\n",
        "\n",
        "          #Backward pass and optimization\n",
        "          optimizer.zero_grad()  # Clear existing gradients\n",
        "          loss.backward()        # Compute gradients\n",
        "          optimizer.step()       # Update parameters\n",
        "          with torch.no_grad():\n",
        "            predictions.extend(torch.argmax(outputs,dim=1).tolist())\n",
        "            true_labels.extend(batch_labels.tolist())\n",
        "        f1.append(f1_score(true_labels, predictions, average='macro'))\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        # Calculate F1 score on validation set\n",
        "        # ...\n",
        "        data = torch.tensor(test_datasets['images'])\n",
        "        target = torch.tensor(test_datasets['labels']).type(torch.LongTensor)\n",
        "        true_labels.extend(target.tolist())\n",
        "        output = model(data)\n",
        "        predictions.extend(torch.argmax(output,dim=1).tolist())\n",
        "        val_f1_score = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "    return f1\n",
        "chromosome = (17,'RELU')\n",
        "f1 = train_fitness(chromosome, datasets, test_datasets)"
      ],
      "metadata": {
        "id": "_O9iGOBPGMlB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "xpoints = np.arange(len(f1))\n",
        "\n",
        "plt.plot(xpoints, f1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L-ybLsv_ODUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "2f8a050f-92ea-4669-fcb1-711a9a6984b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmWfimYu4esS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}